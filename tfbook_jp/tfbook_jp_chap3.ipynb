{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch.3\n",
    "## 3.1 Tensorboard\n",
    "*Tensorboardを利用するために必要なプロセス*  \n",
    "  \n",
    "1. モデル構築時に必要なところでログを取得するオペレーションを記載する。\n",
    "2. 全てログを配置し終わったら、そのログをマージするオペレーションを記載する。\n",
    "3. `tf.summary.FireWriter`を呼び出してログの出力先と対象グラフを指定する。\n",
    "4. ログを取得するタイミングでマージするオペレーションを実行する。\n",
    "5. 実行結果を`FireWriter`に追加する。\n",
    "6. 出力されたログを`tensorboard`コマンドで指定して呼び出す。\n",
    "7. ブラウザで対象サーバーにアクセスする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images\n",
    "バイナリデータ化した画像がモデルに正しく渡っているか、オーギュメンテーション後の画像が判別可能なレベルかなどを確認するのに有効。  \n",
    "input imageが[mini batch size, 784]なので、[mini batch size, hight, width, channel]に変換して表示させる。  \n",
    "  \n",
    "### Graph\n",
    "計算グラフを可視化する`Graph`は、特にログを取得するオペレーションを記載する必要がない。  \n",
    "`FireWriter`を宣言する際に対象のグラフを指定してログ出力ディレクトリを指定した時点で勝手にログが作成される（後述）。  \n",
    "  \n",
    "### name_scope  \n",
    "TensorFlowではシンプルな構成のネットワークでもオペレーションの数が多くなることが少なくない。  \n",
    "しかし、そのままGraphを表示すると、全てのオペレーションが表示されてしまい可読性が下がる。  \n",
    "そこで、`name_scope`を指定して各層や特定の処理ごとにまとめると、整理されてわかりやすくなる。  \n",
    "### Scalars \n",
    "`loss`と`accuracy`の処理の後に`Scalars`を配置する。  \n",
    "`tf.summary.scalar()`の入力値はスカラー（0階テンソル）であることに注意。  \n",
    "→重みやバイアスはスカラーではないので、`Scalars`が使えない。  \n",
    "→そういう場合は`tf.summary.histgram()`を利用する。  \n",
    "  \n",
    "### Distributions / Histogram  \n",
    "引数の制約はほとんど無く、数値データのテンソルであれば何でも構わない。  \n",
    "ただし、NeuralNetworkが発散した場合に`Ｎａｎ`となる場合があり、`Ｎａｎ`がひとつでもあるとエラーを吐くので注意。  \n",
    "`tf.summary.histogram()`に値があれば、TensorBoardでは`Histograms`と`Distributions`の両方で結果を見ることができる。  \n",
    "- Distributions:  確率分布/推移を時間軸ごとに見ることができる  \n",
    "- Histogram:　ステップの度数分布を確認できる  \n",
    "  \n",
    "### Merging  \n",
    "ログのマージには2種類あり、一部のログをマージするものと、全てのログをマージするもの。  \n",
    "当たり前だが、後者は全てのログの配置が終わった後にマージすること。  \n",
    "\n",
    "```\n",
    "# merging some logs\n",
    "merge = tf.summary.merge([a, b, c])\n",
    "\n",
    "# merging all the logs\n",
    "summary_op = tf.summary.merge_all()\n",
    "```\n",
    "\n",
    "### FileWriter\n",
    "取得したログを実際にログファイルに書き出すのが`tf.summary.FireWriter`で、宣言するだけで計算グラフを`Graphs`に出力してくれる。  \n",
    "第一引数はログ出力対象のディレクトリで、絶対パスでも相対パスでも書ける。  \n",
    "  \n",
    "  \n",
    "### TensorBoard  \n",
    "TensorBoardを起動するには、コマンドラインから以下のコマンドを実行する。  \n",
    "（`path/to/log-directory`には実際にログが保存されているパスを入力）  \n",
    "  \n",
    "`tensorboard --logdir /path/to/log-directory`  \n",
    "  \n",
    "起動後は以下のURLからアクセスできる。  \n",
    "http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def mnist_tb():\n",
    "    # importing MNIST data\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    mnist = input_data.read_data_sets('mnist_data/', one_hot=True)\n",
    "\n",
    "    # getting train images, labeled data as batch size = 50\n",
    "    train_images, train_labels = mnist.train.next_batch(50)\n",
    "\n",
    "    # getting all the test images\n",
    "    test_images = mnist.test.images\n",
    "\n",
    "    # getting all the test labels\n",
    "    test_labels = mnist.test.labels\n",
    "\n",
    "    # input layer\n",
    "    # using None for an arbitrary batch size\n",
    "    # this is really useful when train and validation batches\n",
    "    # are different size\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "    # getting a log of the input image\n",
    "    # x is [None, 784] and need a transformation into an image\n",
    "    # img: [size of the mini batch, hight, width, channel]\n",
    "    img = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    tf.summary.image('input_data', img, 10)\n",
    "\n",
    "    # hidden layer\n",
    "    with tf.name_scope('hidden'):\n",
    "        w_1 = tf.Variable(tf.truncated_normal([784, 64], stddev=0.1), name='w1')\n",
    "        b_1 = tf.Variable(tf.zeros([64]), name='b1')\n",
    "        h_1 = tf.nn.relu(tf.matmul(x, w_1) + b_1)\n",
    "\n",
    "        # logging\n",
    "        tf.summary.histogram('w_1', w_1)\n",
    "\n",
    "    # output layer\n",
    "    with tf.name_scope('output'):\n",
    "        w_2 = tf.Variable(tf.truncated_normal([64, 10], stddev=0.1), name='w2')\n",
    "        b_2 = tf.Variable(tf.zeros([10]), name='b2')\n",
    "        out = tf.nn.softmax(tf.matmul(h_1, w_2) + b_2)\n",
    "\n",
    "    # loss function\n",
    "    # computing mean with tf.reduce_mean\n",
    "    y = tf.placeholder(tf.float32, [None, 10])\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.reduce_mean(tf.square(y - out))\n",
    "        # logging\n",
    "        tf.summary.scalar('loss', loss)\n",
    "\n",
    "    # train\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # evaluation\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        # logging\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "    # merging all the logs\n",
    "    summary_op = tf.summary.merge_all()\n",
    "\n",
    "    # defining initializer\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        sess.run(init)\n",
    "\n",
    "        # FileWriter\n",
    "        summary_writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "\n",
    "        # loading test data\n",
    "        test_images = mnist.test.images\n",
    "        test_labels = mnist.test.labels\n",
    "\n",
    "        for i in range(1000):\n",
    "            step = i + 1\n",
    "            train_images, train_labels = mnist.train.next_batch(50)\n",
    "            sess.run(train_step, feed_dict={x:train_images, y:train_labels})\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                # logging (outputs are protocol buffers of logs)\n",
    "                summary_str = sess.run(summary_op,\n",
    "                                       feed_dict={x:test_images, y:test_labels})\n",
    "                # writing protocol buffers of logs\n",
    "                summary_writer.add_summary(summary_str, step)\n",
    "\n",
    "                # computing and printing accuracy\n",
    "                acc_val = sess.run(accuracy,\n",
    "                                   feed_dict={x:test_images, y:test_labels})\n",
    "                print('Step {}: accuracy = {}'.format(step, acc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-071089a5b051>:12: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/tk/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/tk/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/tk/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/tk/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/tk/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Step 10: accuracy = 0.14470000565052032\n",
      "Step 20: accuracy = 0.18539999425411224\n",
      "Step 30: accuracy = 0.23000000417232513\n",
      "Step 40: accuracy = 0.2732999920845032\n",
      "Step 50: accuracy = 0.3125999867916107\n",
      "Step 60: accuracy = 0.3368000090122223\n",
      "Step 70: accuracy = 0.3635999858379364\n",
      "Step 80: accuracy = 0.39910000562667847\n",
      "Step 90: accuracy = 0.44920000433921814\n",
      "Step 100: accuracy = 0.4837000072002411\n",
      "Step 110: accuracy = 0.5174000263214111\n",
      "Step 120: accuracy = 0.5364999771118164\n",
      "Step 130: accuracy = 0.5561000108718872\n",
      "Step 140: accuracy = 0.579800009727478\n",
      "Step 150: accuracy = 0.5982000231742859\n",
      "Step 160: accuracy = 0.6068999767303467\n",
      "Step 170: accuracy = 0.6132000088691711\n",
      "Step 180: accuracy = 0.6384999752044678\n",
      "Step 190: accuracy = 0.6536999940872192\n",
      "Step 200: accuracy = 0.6736999750137329\n",
      "Step 210: accuracy = 0.6811000108718872\n",
      "Step 220: accuracy = 0.6855000257492065\n",
      "Step 230: accuracy = 0.6901000142097473\n",
      "Step 240: accuracy = 0.7099999785423279\n",
      "Step 250: accuracy = 0.7193999886512756\n",
      "Step 260: accuracy = 0.7232000231742859\n",
      "Step 270: accuracy = 0.7473000288009644\n",
      "Step 280: accuracy = 0.7702999711036682\n",
      "Step 290: accuracy = 0.776199996471405\n",
      "Step 300: accuracy = 0.7682999968528748\n",
      "Step 310: accuracy = 0.7997999787330627\n",
      "Step 320: accuracy = 0.8015999794006348\n",
      "Step 330: accuracy = 0.8141000270843506\n",
      "Step 340: accuracy = 0.8091999888420105\n",
      "Step 350: accuracy = 0.8145999908447266\n",
      "Step 360: accuracy = 0.8222000002861023\n",
      "Step 370: accuracy = 0.8325999975204468\n",
      "Step 380: accuracy = 0.8371000289916992\n",
      "Step 390: accuracy = 0.8348000049591064\n",
      "Step 400: accuracy = 0.8392000198364258\n",
      "Step 410: accuracy = 0.8367000222206116\n",
      "Step 420: accuracy = 0.8374000191688538\n",
      "Step 430: accuracy = 0.8471999764442444\n",
      "Step 440: accuracy = 0.8474000096321106\n",
      "Step 450: accuracy = 0.8381999731063843\n",
      "Step 460: accuracy = 0.8485000133514404\n",
      "Step 470: accuracy = 0.8557999730110168\n",
      "Step 480: accuracy = 0.8578000068664551\n",
      "Step 490: accuracy = 0.8608999848365784\n",
      "Step 500: accuracy = 0.8574000000953674\n",
      "Step 510: accuracy = 0.8621000051498413\n",
      "Step 520: accuracy = 0.8651999831199646\n",
      "Step 530: accuracy = 0.8648999929428101\n",
      "Step 540: accuracy = 0.8683000206947327\n",
      "Step 550: accuracy = 0.8671000003814697\n",
      "Step 560: accuracy = 0.8668000102043152\n",
      "Step 570: accuracy = 0.8686000108718872\n",
      "Step 580: accuracy = 0.866599977016449\n",
      "Step 590: accuracy = 0.8693000078201294\n",
      "Step 600: accuracy = 0.8723999857902527\n",
      "Step 610: accuracy = 0.8727999925613403\n",
      "Step 620: accuracy = 0.8726000189781189\n",
      "Step 630: accuracy = 0.8747000098228455\n",
      "Step 640: accuracy = 0.8751999735832214\n",
      "Step 650: accuracy = 0.8763999938964844\n",
      "Step 660: accuracy = 0.8743000030517578\n",
      "Step 670: accuracy = 0.8726999759674072\n",
      "Step 680: accuracy = 0.8772000074386597\n",
      "Step 690: accuracy = 0.8787999749183655\n",
      "Step 700: accuracy = 0.8784999847412109\n",
      "Step 710: accuracy = 0.8792999982833862\n",
      "Step 720: accuracy = 0.8805999755859375\n",
      "Step 730: accuracy = 0.8787999749183655\n",
      "Step 740: accuracy = 0.8797000050544739\n",
      "Step 750: accuracy = 0.8831999897956848\n",
      "Step 760: accuracy = 0.881600022315979\n",
      "Step 770: accuracy = 0.8858000040054321\n",
      "Step 780: accuracy = 0.883899986743927\n",
      "Step 790: accuracy = 0.8855999708175659\n",
      "Step 800: accuracy = 0.881600022315979\n",
      "Step 810: accuracy = 0.8853999972343445\n",
      "Step 820: accuracy = 0.8823999762535095\n",
      "Step 830: accuracy = 0.8858000040054321\n",
      "Step 840: accuracy = 0.8840000033378601\n",
      "Step 850: accuracy = 0.8884000182151794\n",
      "Step 860: accuracy = 0.8878999948501587\n",
      "Step 870: accuracy = 0.887499988079071\n",
      "Step 880: accuracy = 0.8859000205993652\n",
      "Step 890: accuracy = 0.8862000107765198\n",
      "Step 900: accuracy = 0.8884999752044678\n",
      "Step 910: accuracy = 0.8913000226020813\n",
      "Step 920: accuracy = 0.890999972820282\n",
      "Step 930: accuracy = 0.8921999931335449\n",
      "Step 940: accuracy = 0.8917999863624573\n",
      "Step 950: accuracy = 0.8894000053405762\n",
      "Step 960: accuracy = 0.8881000280380249\n",
      "Step 970: accuracy = 0.89410001039505\n",
      "Step 980: accuracy = 0.8939999938011169\n",
      "Step 990: accuracy = 0.8937000036239624\n",
      "Step 1000: accuracy = 0.8952000141143799\n"
     ]
    }
   ],
   "source": [
    "mnist_tb()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
