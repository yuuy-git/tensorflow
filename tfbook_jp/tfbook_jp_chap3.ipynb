{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch.3\n",
    "## 3.1 Tensorboard\n",
    "*Tensorboardを利用するために必要なプロセス*  \n",
    "  \n",
    "1. モデル構築時に必要なところでログを取得するオペレーションを記載する。\n",
    "2. 全てログを配置し終わったら、そのログをマージするオペレーションを記載する。\n",
    "3. `tf.summary.FireWriter`を呼び出してログの出力先と対象グラフを指定する。\n",
    "4. ログを取得するタイミングでマージするオペレーションを実行する。\n",
    "5. 実行結果を`FireWriter`に追加する。\n",
    "6. 出力されたログを`tensorboard`コマンドで指定して呼び出す。\n",
    "7. ブラウザで対象サーバーにアクセスする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images\n",
    "バイナリデータ化した画像がモデルに正しく渡っているか、オーギュメンテーション後の画像が判別可能なレベルかなどを確認するのに有効。  \n",
    "input imageが[mini batch size, 784]なので、[mini batch size, hight, width, channel]に変換して表示させる。  \n",
    "  \n",
    "### Graph\n",
    "計算グラフを可視化する`Graph`は、特にログを取得するオペレーションを記載する必要がない。  \n",
    "`FireWriter`を宣言する際に対象のグラフを指定してログ出力ディレクトリを指定した時点で勝手にログが作成される（後述）。  \n",
    "  \n",
    "### name_scope  \n",
    "TensorFlowではシンプルな構成のネットワークでもオペレーションの数が多くなることが少なくない。  \n",
    "しかし、そのままGraphを表示すると、全てのオペレーションが表示されてしまい可読性が下がる。  \n",
    "そこで、`name_scope`を指定して各層や特定の処理ごとにまとめると、整理されてわかりやすくなる。  \n",
    "### Scalars \n",
    "`loss`と`accuracy`の処理の後に`Scalars`を配置する。  \n",
    "`tf.summary.scalar()`の入力値はスカラー（0階テンソル）であることに注意。  \n",
    "→重みやバイアスはスカラーではないので、`Scalars`が使えない。  \n",
    "→そういう場合は`tf.summary.histgram()`を利用する。  \n",
    "  \n",
    "### Distributions / Histogram  \n",
    "引数の制約はほとんど無く、数値データのテンソルであれば何でも構わない。  \n",
    "ただし、NeuralNetworkが発散した場合に`Ｎａｎ`となる場合があり、`Ｎａｎ`がひとつでもあるとエラーを吐くので注意。  \n",
    "`tf.summary.histogram()`に値があれば、TensorBoardでは`Histograms`と`Distributions`の両方で結果を見ることができる。  \n",
    "- Distributions:  確率分布/推移を時間軸ごとに見ることができる  \n",
    "- Histogram:　ステップの度数分布を確認できる  \n",
    "  \n",
    "### Merging  \n",
    "ログのマージには2種類あり、一部のログをマージするものと、全てのログをマージするもの。  \n",
    "当たり前だが、後者は全てのログの配置が終わった後にマージすること。  \n",
    "\n",
    "```\n",
    "# merging some logs\n",
    "merge = tf.summary.merge([a, b, c])\n",
    "\n",
    "# merging all the logs\n",
    "summary_op = tf.summary.merge_all()\n",
    "```\n",
    "\n",
    "### FileWriter\n",
    "取得したログを実際にログファイルに書き出すのが`tf.summary.FireWriter`で、宣言するだけで計算グラフを`Graphs`に出力してくれる。  \n",
    "第一引数はログ出力対象のディレクトリで、絶対パスでも相対パスでも書ける。  \n",
    "  \n",
    "  \n",
    "### TensorBoard  \n",
    "TensorBoardを起動するには、コマンドラインから以下のコマンドを実行する。  \n",
    "（`path/to/log-directory`には実際にログが保存されているパスを入力）  \n",
    "  \n",
    "`tensorboard --logdir /path/to/log-directory`  \n",
    "  \n",
    "起動後は以下のURLからアクセスできる。  \n",
    "http://localhost:6006\n",
    "\n",
    "## mnist_tb()について\n",
    "1行あたりの長さを気にせず書いたので、やはり見にくい。  \n",
    "下の`mnist_cnn()`と比べると読みづらさがわかる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def mnist_tb():\n",
    "    # importing MNIST data\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    mnist = input_data.read_data_sets('mnist_data/', one_hot=True)\n",
    "\n",
    "    # getting train images, labeled data as batch size = 50\n",
    "    train_images, train_labels = mnist.train.next_batch(50)\n",
    "\n",
    "    # getting all the test images\n",
    "    test_images = mnist.test.images\n",
    "\n",
    "    # getting all the test labels\n",
    "    test_labels = mnist.test.labels\n",
    "\n",
    "    # input layer\n",
    "    # using None for an arbitrary batch size\n",
    "    # this is really useful when train and validation batches\n",
    "    # are different size\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "    # getting a log of the input image\n",
    "    # x is [None, 784] and need a transformation into an image\n",
    "    # img: [size of the mini batch, hight, width, channel]\n",
    "    img = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    tf.summary.image('input_data', img, 10)\n",
    "\n",
    "    # hidden layer\n",
    "    with tf.name_scope('hidden'):\n",
    "        w_1 = tf.Variable(tf.truncated_normal([784, 64], stddev=0.1), name='w1')\n",
    "        b_1 = tf.Variable(tf.zeros([64]), name='b1')\n",
    "        h_1 = tf.nn.relu(tf.matmul(x, w_1) + b_1)\n",
    "\n",
    "        # logging\n",
    "        tf.summary.histogram('w_1', w_1)\n",
    "\n",
    "    # output layer\n",
    "    with tf.name_scope('output'):\n",
    "        w_2 = tf.Variable(tf.truncated_normal([64, 10], stddev=0.1), name='w2')\n",
    "        b_2 = tf.Variable(tf.zeros([10]), name='b2')\n",
    "        out = tf.nn.softmax(tf.matmul(h_1, w_2) + b_2)\n",
    "\n",
    "    # loss function\n",
    "    # computing mean with tf.reduce_mean\n",
    "    y = tf.placeholder(tf.float32, [None, 10])\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.reduce_mean(tf.square(y - out))\n",
    "        # logging\n",
    "        tf.summary.scalar('loss', loss)\n",
    "\n",
    "    # train\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # evaluation\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        # logging\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "    # merging all the logs\n",
    "    summary_op = tf.summary.merge_all()\n",
    "\n",
    "    # defining initializer\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        sess.run(init)\n",
    "\n",
    "        # FileWriter\n",
    "        summary_writer = tf.summary.FileWriter('logs_mnist_tb', sess.graph)\n",
    "\n",
    "        # loading test data\n",
    "        test_images = mnist.test.images\n",
    "        test_labels = mnist.test.labels\n",
    "\n",
    "        for i in range(1000):\n",
    "            step = i + 1\n",
    "            train_images, train_labels = mnist.train.next_batch(50)\n",
    "            sess.run(train_step, feed_dict={x:train_images, y:train_labels})\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                # logging (outputs are protocol buffers of logs)\n",
    "                summary_str = sess.run(summary_op,\n",
    "                                       feed_dict={x:test_images, y:test_labels})\n",
    "                # writing protocol buffers of logs\n",
    "                summary_writer.add_summary(summary_str, step)\n",
    "\n",
    "                # computing and printing accuracy\n",
    "                acc_val = sess.run(accuracy,\n",
    "                                   feed_dict={x:test_images, y:test_labels})\n",
    "                print('Step {}: accuracy = {}'.format(step, acc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-981e0a8bcd80>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/tk/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/tk/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/tk/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/tk/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/tk/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Step 10: accuracy = 0.15309999883174896\n",
      "Step 20: accuracy = 0.17790000140666962\n",
      "Step 30: accuracy = 0.2354000061750412\n",
      "Step 40: accuracy = 0.28139999508857727\n",
      "Step 50: accuracy = 0.3224000036716461\n",
      "Step 60: accuracy = 0.36329999566078186\n",
      "Step 70: accuracy = 0.39910000562667847\n",
      "Step 80: accuracy = 0.4325000047683716\n",
      "Step 90: accuracy = 0.44699999690055847\n",
      "Step 100: accuracy = 0.4661000072956085\n",
      "Step 110: accuracy = 0.4959999918937683\n",
      "Step 120: accuracy = 0.5060999989509583\n",
      "Step 130: accuracy = 0.5175999999046326\n",
      "Step 140: accuracy = 0.5364999771118164\n",
      "Step 150: accuracy = 0.5561000108718872\n",
      "Step 160: accuracy = 0.5733000040054321\n",
      "Step 170: accuracy = 0.5971999764442444\n",
      "Step 180: accuracy = 0.6085000038146973\n",
      "Step 190: accuracy = 0.6255999803543091\n",
      "Step 200: accuracy = 0.6277999877929688\n",
      "Step 210: accuracy = 0.6373000144958496\n",
      "Step 220: accuracy = 0.6547999978065491\n",
      "Step 230: accuracy = 0.6646000146865845\n",
      "Step 240: accuracy = 0.6818000078201294\n",
      "Step 250: accuracy = 0.6963000297546387\n",
      "Step 260: accuracy = 0.7027999758720398\n",
      "Step 270: accuracy = 0.715499997138977\n",
      "Step 280: accuracy = 0.7324000000953674\n",
      "Step 290: accuracy = 0.7450000047683716\n",
      "Step 300: accuracy = 0.7526000142097473\n",
      "Step 310: accuracy = 0.7577000260353088\n",
      "Step 320: accuracy = 0.7627999782562256\n",
      "Step 330: accuracy = 0.763700008392334\n",
      "Step 340: accuracy = 0.7709000110626221\n",
      "Step 350: accuracy = 0.7789000272750854\n",
      "Step 360: accuracy = 0.7889000177383423\n",
      "Step 370: accuracy = 0.7922999858856201\n",
      "Step 380: accuracy = 0.8098999857902527\n",
      "Step 390: accuracy = 0.8033000230789185\n",
      "Step 400: accuracy = 0.8162000179290771\n",
      "Step 410: accuracy = 0.8227999806404114\n",
      "Step 420: accuracy = 0.8208000063896179\n",
      "Step 430: accuracy = 0.8269000053405762\n",
      "Step 440: accuracy = 0.8270999789237976\n",
      "Step 450: accuracy = 0.8335999846458435\n",
      "Step 460: accuracy = 0.8420000076293945\n",
      "Step 470: accuracy = 0.8425999879837036\n",
      "Step 480: accuracy = 0.8454999923706055\n",
      "Step 490: accuracy = 0.8482999801635742\n",
      "Step 500: accuracy = 0.850600004196167\n",
      "Step 510: accuracy = 0.8507999777793884\n",
      "Step 520: accuracy = 0.8515999913215637\n",
      "Step 530: accuracy = 0.8561999797821045\n",
      "Step 540: accuracy = 0.8564000129699707\n",
      "Step 550: accuracy = 0.8615000247955322\n",
      "Step 560: accuracy = 0.861299991607666\n",
      "Step 570: accuracy = 0.8600999712944031\n",
      "Step 580: accuracy = 0.8605999946594238\n",
      "Step 590: accuracy = 0.8640999794006348\n",
      "Step 600: accuracy = 0.8589000105857849\n",
      "Step 610: accuracy = 0.8636999726295471\n",
      "Step 620: accuracy = 0.8689000010490417\n",
      "Step 630: accuracy = 0.870199978351593\n",
      "Step 640: accuracy = 0.8720999956130981\n",
      "Step 650: accuracy = 0.8745999932289124\n",
      "Step 660: accuracy = 0.8747000098228455\n",
      "Step 670: accuracy = 0.8756999969482422\n",
      "Step 680: accuracy = 0.8761000037193298\n",
      "Step 690: accuracy = 0.8766999840736389\n",
      "Step 700: accuracy = 0.8759999871253967\n",
      "Step 710: accuracy = 0.8741000294685364\n",
      "Step 720: accuracy = 0.8797000050544739\n",
      "Step 730: accuracy = 0.8794999718666077\n",
      "Step 740: accuracy = 0.8822000026702881\n",
      "Step 750: accuracy = 0.8830999732017517\n",
      "Step 760: accuracy = 0.8824999928474426\n",
      "Step 770: accuracy = 0.8830999732017517\n",
      "Step 780: accuracy = 0.8783000111579895\n",
      "Step 790: accuracy = 0.8835999965667725\n",
      "Step 800: accuracy = 0.8812999725341797\n",
      "Step 810: accuracy = 0.8823999762535095\n",
      "Step 820: accuracy = 0.8845999836921692\n",
      "Step 830: accuracy = 0.8862000107765198\n",
      "Step 840: accuracy = 0.8889999985694885\n",
      "Step 850: accuracy = 0.8888000249862671\n",
      "Step 860: accuracy = 0.8852999806404114\n",
      "Step 870: accuracy = 0.8859999775886536\n",
      "Step 880: accuracy = 0.8899000287055969\n",
      "Step 890: accuracy = 0.8909000158309937\n",
      "Step 900: accuracy = 0.8877000212669373\n",
      "Step 910: accuracy = 0.8921999931335449\n",
      "Step 920: accuracy = 0.8914999961853027\n",
      "Step 930: accuracy = 0.8881999850273132\n",
      "Step 940: accuracy = 0.8921999931335449\n",
      "Step 950: accuracy = 0.8899999856948853\n",
      "Step 960: accuracy = 0.8952000141143799\n",
      "Step 970: accuracy = 0.8949999809265137\n",
      "Step 980: accuracy = 0.8942000269889832\n",
      "Step 990: accuracy = 0.8935999870300293\n",
      "Step 1000: accuracy = 0.8981000185012817\n"
     ]
    }
   ],
   "source": [
    "mnist_tb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Changing for a better neural network\n",
    "  \n",
    "In this section we will improve the network we made above by the following actions:  \n",
    "  \n",
    "- changing to a multi-layer network   \n",
    "- introducing a convolutional neural network  \n",
    "- setting *cross entropy* as the loss function \n",
    "  \n",
    "今までのモデル：多層パーセプトロン  \n",
    "→左上からピクセルが白か黒かということを精査して数字を判別しているだけ  \n",
    "→これでは「どこに丸みがある」「どこに角がある」などの画像の特徴を利用していない  \n",
    "→そこで特徴を抽出してそれを基に分類するCNNを導入する  \n",
    "  \n",
    "CNNの説明は省略。  \n",
    "復習したい場合は[このブログ](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/)か[この動画](https://youtu.be/2-Ol7ZB0MmU)がオススメ。  \n",
    "  \n",
    "クロスエントロピーには微小量を加算しないと、log0に限りなく近い値を取り、ニューラルネットワークが発散してしまう場合があるので要注意。  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def mnist_cnn():\n",
    "    # importing MNIST data\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    mnist = input_data.read_data_sets('mnist_data/', one_hot=True)\n",
    "\n",
    "    # getting train images, labeled data as batch size = 50\n",
    "    train_images, train_labels = mnist.train.next_batch(50)\n",
    "\n",
    "    # getting all the test images\n",
    "    test_images = mnist.test.images\n",
    "\n",
    "    # getting all the test labels\n",
    "    test_labels = mnist.test.labels\n",
    "\n",
    "    # input layer\n",
    "    # using None for an arbitrary batch size\n",
    "    # this is really useful when train and validation batches\n",
    "    # are different size\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "    # getting a log of the input image\n",
    "    # x is [None, 784] and need a transformation into an image\n",
    "    # img: [size of the mini batch, hight, width, channel]\n",
    "    img = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    tf.summary.image('input_data', img, 10)\n",
    "\n",
    "    # conv1 layer\n",
    "    #\n",
    "    # Architecture:\n",
    "    #  input: [1, 28, 28, 1]\n",
    "    #  output: [1, 14, 14, 32]\n",
    "    #  where [batch, hight, width, channels]\n",
    "    #\n",
    "    # Prams:\n",
    "    #  f1: [hight, width, channels, num of filters (channels after convolution)]\n",
    "    #  strides: [batch, hight, width, channels]\n",
    "    #\n",
    "    # Filters:\n",
    "    #  filters in CNN correspond to weights in neural networks,\n",
    "    #  so use tf.Variable as defining filters\n",
    "    #  f: [hight, width, channels, num of filters (channels after convolution)]\n",
    "    #  usually initialized with tf.truncated_normal()\n",
    "    with tf.name_scope('conv_block1'):\n",
    "        f1 = tf.Variable(tf.truncated_normal([5, 5, 1, 32],\n",
    "                                             stddev=0.1), name='f1')\n",
    "        conv1 = tf.nn.conv2d(img, f1, strides=[1, 1, 1, 1],\n",
    "                             padding='SAME', name='conv1')\n",
    "        b1 = tf.Variable(tf.constant(0.1, shape=[32], name='b1'))\n",
    "        h_conv1 = tf.nn.relu(conv1 + b1)\n",
    "        h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1],\n",
    "                                 strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        # logging\n",
    "        tf.summary.histogram('f1', f1)\n",
    "        tf.summary.histogram('b1', b1)\n",
    "\n",
    "    # conv2 layer\n",
    "    #\n",
    "    # Architecture:\n",
    "    #  input: [1, 14, 14, 32]\n",
    "    #  output: [1, 7, 7, 64]\n",
    "    #  where [batch, hight, width, channels]\n",
    "    with tf.name_scope('conv_block2'):\n",
    "        f2 = tf.Variable(tf.truncated_normal([5, 5, 32, 64],\n",
    "                                             stddev=0.1), name='f2')\n",
    "        conv2 = tf.nn.conv2d(h_pool1, f2, strides=[1, 1, 1, 1],\n",
    "                             padding='SAME', name='conv2')\n",
    "        b2 = tf.Variable(tf.constant(0.1, shape=[64], name='b2'))\n",
    "        h_conv2 = tf.nn.relu(conv2 + b2)\n",
    "        h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1],\n",
    "                                 strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        # logging\n",
    "        tf.summary.histogram('f2', f2)\n",
    "        tf.summary.histogram('b2', b2)\n",
    "\n",
    "   # fully connected layer\n",
    "    with tf.name_scope('fully_connected_layer'):\n",
    "        # flattening the convoluted output\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "\n",
    "        # fully connected layer\n",
    "        w_fc1 = tf.Variable(tf.truncated_normal([7*7*64, 1024],\n",
    "                                                stddev=0.1), name='w_fc1')\n",
    "        b_fc1 = tf.Variable(tf.constant(0.1, shape=[1024]), name='b_fc1')\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, w_fc1) + b_fc1)\n",
    "\n",
    "        # output layer\n",
    "        w_fc2 = tf.Variable(tf.truncated_normal([1024, 10],\n",
    "                                                stddev=0.1), name='w_fc2')\n",
    "        b_fc2 = tf.Variable(tf.constant(0.1, shape=[10]), name='b_fc2')\n",
    "        out = tf.nn.softmax(tf.matmul(h_fc1, w_fc2) + b_fc2)\n",
    "\n",
    "    # loss function\n",
    "    # using cross entropy as loss function\n",
    "    y = tf.placeholder(tf.float32, [None, 10])\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(out + 1e-5), axis=[1]))\n",
    "\n",
    "        # logging\n",
    "        tf.summary.scalar('loss', loss)\n",
    "\n",
    "    # train\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "\n",
    "    # evaluation\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        # logging\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "    # merging all the logs\n",
    "    summary_op = tf.summary.merge_all()\n",
    "\n",
    "    # defining initializer\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # excecution\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        # FileWriter\n",
    "        summary_writer = tf.summary.FileWriter('logs_mnist_cnn', sess.graph)\n",
    "\n",
    "        # loading test data\n",
    "        test_images = mnist.test.images\n",
    "        test_labels = mnist.test.labels\n",
    "\n",
    "        for i in range(1000):\n",
    "            step = i + 1\n",
    "            train_images, train_labels = mnist.train.next_batch(50)\n",
    "            sess.run(train_step, feed_dict={x:train_images, y:train_labels})\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                # logging (outputs are protocol buffers of logs)\n",
    "                summary_str = sess.run(summary_op,\n",
    "                                       feed_dict={x:test_images, y:test_labels})\n",
    "                # writing protocol buffers of logs\n",
    "                summary_writer.add_summary(summary_str, step)\n",
    "\n",
    "                # computing and printing accuracy\n",
    "                acc_val = sess.run(accuracy,\n",
    "                                   feed_dict={x:test_images, y:test_labels})\n",
    "                print('Step {}: accuracy = {}'.format(step, acc_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mnist_cnn()` killed my kernel, so I recommend you to reset the kernel after excecuting every model or just excecute on AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  [[1 1 1]\n",
      " [1 1 1]]\n",
      "tf.reduce_sum(x):  6\n",
      "tf.reduce_sum(x, 0):  [2 2 2]\n",
      "tf.reduce_sum(x, 1):  [3 3]\n",
      "tf.reduce_sum(x, 1, keepdims=True):  [[3]\n",
      " [3]]\n",
      "tf.reduce_sum(x, [0, 1]):  6\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# reduce_sum() examples\n",
    "x = tf.constant([[1, 1, 1], [1, 1, 1]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('x: ', sess.run(x))\n",
    "    print('tf.reduce_sum(x): ',\n",
    "          sess.run(tf.reduce_sum(x)))  # 6\n",
    "    print('tf.reduce_sum(x, 0): ',\n",
    "          sess.run(tf.reduce_sum(x, 0)))  # [2, 2, 2]\n",
    "    print('tf.reduce_sum(x, 1): ',\n",
    "          sess.run(tf.reduce_sum(x, 1)))  # [3, 3]\n",
    "    print('tf.reduce_sum(x, 1, keepdims=True): ',\n",
    "          sess.run(tf.reduce_sum(x, 1, keepdims=True)))  # [[3], [3]]\n",
    "    print('tf.reduce_sum(x, [0, 1]): ',\n",
    "          sess.run(tf.reduce_sum(x, [0, 1])))  # 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Saver\n",
    "### Saving\n",
    "モデルの保存にはいくつか方法があるが、以下の方法が一番シンプル。  \n",
    "まずはセッションの前に`saver`を定義する。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### THIS DOSEN'T WORK ###########\n",
    "\n",
    "# saving all the models and variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# list is available\n",
    "saver = tf.train.Saver([w1, w1])\n",
    "\n",
    "# dict is also available\n",
    "saver = tf.train.Saver({'param1':w1, 'param2':w2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に学習が終わった後に`saver.save(sess, 'PATH/NAME')`で`saver`を実行する。  \n",
    "この方法だと全ての学習が終わった後のモデルしか保存できないが、実際には一定回数ごとにモデルを保存しておき、一番精度が高かったモデルを利用することが多い。  \n",
    "そのためには、`acc_val`のスコープ内で`saver`を実行し、ループさせる必要がある。  \n",
    "このとき、`global_step`引数でステップ数を指定する。  \n",
    "  \n",
    "モデルの保存には容量が必要なので、保存数に上限が設けられていることに注意する。  \n",
    "`max_to_keep`でこれを指定しており、デフォルトは5。  \n",
    "  \n",
    "また、グラフの構造などを記述するmetaファイルも毎回書き込みが行われるが、基本的には学習中に用いるモデルが不変なので、この書き込みは省いたほうが良い。  \n",
    "しかもmetaファイルはモデルの設計コードがなくてもモデルを読み込むための復元ファイルみたいなものなので、今回のように手元にソースコードがある場合は不要である。  \n",
    "そういう場合は`write_meta_graph=False`と指定する。  \n",
    "  \n",
    "如何に計算を効率化しても、このようなlog出力やチェックポイントファイルの出力がボトルネックになって学習が進まないということが多々あるので、実際に運用する際には気を付ける。\n",
    "\n",
    "### global_step\n",
    "上記に加えて、学習を中断した際に、正しいステップ数から再開するために`global_step`を正しく指定する必要がある。  \n",
    "この設定をせずに再開できないモデルを設計してしまうと、TensorBoardと組み合わせて利用したい時に困るらしい。  \n",
    "そこで、`global_step`もモデル内に保存し、環境が変わってもステップ数を読み込めるようにする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "train_step = tf.train.Gradient.DescentOptimizer(0.5)\\\n",
    "    .minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`minimize`メソッドの第二引数に`global_step`を指定することで、trainごとにincrementしてくれるようになる。\n",
    "`trainable=False`は、計算グラフの訓練対象の`Variable()`コレクションに`global_step`を加えないための措置。  \n",
    "モデルが複雑になると、訓練用の変数を全て取得して処理を行うこともあるので、習慣的に`global_step`は`trainable=False`にする。  \n",
    "あとはtrain loop前に`global_step`を実行し、ステップ数を計算してからtrainを実行させる。  \n",
    "最終的なコードは以下の通り。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def mnist_saver():\n",
    "    # importing MNIST data\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    mnist = input_data.read_data_sets('mnist_data/', one_hot=True)\n",
    "\n",
    "    # getting train images, labeled data as batch size = 50\n",
    "    train_images, train_labels = mnist.train.next_batch(50)\n",
    "\n",
    "    # getting all the test images\n",
    "    test_images = mnist.test.images\n",
    "\n",
    "    # getting all the test labels\n",
    "    test_labels = mnist.test.labels\n",
    "\n",
    "    # input layer\n",
    "    # using None for an arbitrary batch size\n",
    "    # this is really useful when train and validation batches\n",
    "    # are different size\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "    # getting a log of the input image\n",
    "    # x is [None, 784] and need a transformation into an image\n",
    "    # img: [size of the mini batch, hight, width, channel]\n",
    "    img = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    tf.summary.image('input_data', img, 10)\n",
    "\n",
    "    # conv1 layer\n",
    "    #\n",
    "    # Architecture:\n",
    "    #  input: [1, 28, 28, 1]\n",
    "    #  output: [1, 14, 14, 32]\n",
    "    #  where [batch, hight, width, channels]\n",
    "    #\n",
    "    # Prams:\n",
    "    #  f1: [hight, width, channels, num of filters (channels after convolution)]\n",
    "    #  strides: [batch, hight, width, channels]\n",
    "    #\n",
    "    # Filters:\n",
    "    #  filters in CNN correspond to weights in neural networks,\n",
    "    #  so use tf.Variable as defining filters\n",
    "    #  f: [hight, width, channels, num of filters (channels after convolution)]\n",
    "    #  usually initialized with tf.truncated_normal()\n",
    "    with tf.name_scope('conv_block1'):\n",
    "        f1 = tf.Variable(tf.truncated_normal([5, 5, 1, 32],\n",
    "                                             stddev=0.1), name='f1')\n",
    "        conv1 = tf.nn.conv2d(img, f1, strides=[1, 1, 1, 1],\n",
    "                             padding='SAME', name='conv1')\n",
    "        b1 = tf.Variable(tf.constant(0.1, shape=[32], name='b1'))\n",
    "        h_conv1 = tf.nn.relu(conv1 + b1)\n",
    "        h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1],\n",
    "                                 strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        # logging\n",
    "        tf.summary.histogram('f1', f1)\n",
    "        tf.summary.histogram('b1', b1)\n",
    "\n",
    "    # conv2 layer\n",
    "    #\n",
    "    # Architecture:\n",
    "    #  input: [1, 14, 14, 32]\n",
    "    #  output: [1, 7, 7, 64]\n",
    "    #  where [batch, hight, width, channels]\n",
    "    with tf.name_scope('conv_block2'):\n",
    "        f2 = tf.Variable(tf.truncated_normal([5, 5, 32, 64],\n",
    "                                             stddev=0.1), name='f2')\n",
    "        conv2 = tf.nn.conv2d(h_pool1, f2, strides=[1, 1, 1, 1],\n",
    "                             padding='SAME', name='conv2')\n",
    "        b2 = tf.Variable(tf.constant(0.1, shape=[64], name='b2'))\n",
    "        h_conv2 = tf.nn.relu(conv2 + b2)\n",
    "        h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1],\n",
    "                                 strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        # logging\n",
    "        tf.summary.histogram('f2', f2)\n",
    "        tf.summary.histogram('b2', b2)\n",
    "\n",
    "   # fully connected layer\n",
    "    with tf.name_scope('fully_connected_layer'):\n",
    "        # flattening the convoluted output\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "\n",
    "        # fully connected layer\n",
    "        w_fc1 = tf.Variable(tf.truncated_normal([7*7*64, 1024],\n",
    "                                                stddev=0.1), name='w_fc1')\n",
    "        b_fc1 = tf.Variable(tf.constant(0.1, shape=[1024]), name='b_fc1')\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, w_fc1) + b_fc1)\n",
    "\n",
    "        # output layer\n",
    "        w_fc2 = tf.Variable(tf.truncated_normal([1024, 10],\n",
    "                                                stddev=0.1), name='w_fc2')\n",
    "        b_fc2 = tf.Variable(tf.constant(0.1, shape=[10]), name='b_fc2')\n",
    "        out = tf.nn.softmax(tf.matmul(h_fc1, w_fc2) + b_fc2)\n",
    "\n",
    "    # loss function\n",
    "    # using cross entropy as loss function\n",
    "    y = tf.placeholder(tf.float32, [None, 10])\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(out + 1e-5), axis=[1]))\n",
    "\n",
    "        # logging\n",
    "        tf.summary.scalar('loss', loss)\n",
    "\n",
    "    # train\n",
    "    with tf.name_scope('train'):\n",
    "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.01)\\\n",
    "            .minimize(loss, global_step=global_step)\n",
    "\n",
    "    # evaluation\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        # logging\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "    # merging all the logs\n",
    "    summary_op = tf.summary.merge_all()\n",
    "\n",
    "    # defining initializer\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # defining saver\n",
    "    saver = tf.train.Saver(max_to_keep=3)\n",
    "\n",
    "    # excecution\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        # FileWriter\n",
    "        summary_writer = tf.summary.FileWriter('logs_mnist_saver', sess.graph)\n",
    "\n",
    "        # loading test data\n",
    "        test_images = mnist.test.images\n",
    "        test_labels = mnist.test.labels\n",
    "\n",
    "        # loading global_step\n",
    "        last_step = sess.run(global_step)\n",
    "\n",
    "        for i in range(1000):\n",
    "            step = last_step + i\n",
    "            train_images, train_labels = mnist.train.next_batch(50)\n",
    "            sess.run(train_step, feed_dict={x:train_images, y:train_labels})\n",
    "\n",
    "            if (step + 1) % 100 == 0:\n",
    "                # logging (outputs are protocol buffers of logs)\n",
    "                summary_str = sess.run(summary_op,\n",
    "                                       feed_dict={x:test_images, y:test_labels})\n",
    "                # writing protocol buffers of logs\n",
    "                summary_writer.add_summary(summary_str, step)\n",
    "\n",
    "                # computing and printing accuracy\n",
    "                acc_val = sess.run(accuracy,\n",
    "                                   feed_dict={x:test_images, y:test_labels})\n",
    "\n",
    "                # showing the accuracy during training \n",
    "                print('Step {}: accuracy = {}'.format(step + 1, acc_val))\n",
    "\n",
    "                # saving models\n",
    "                saver.save(sess, 'ckpt/mnist_saver',\n",
    "                           global_step=step + 1, write_meta_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-9ab5e3977dfa>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/tk/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/tk/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/tk/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/tk/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/tk/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Step 100: accuracy = 0.8689000010490417\n",
      "Step 200: accuracy = 0.9211999773979187\n",
      "Step 300: accuracy = 0.9406999945640564\n",
      "Step 400: accuracy = 0.9422000050544739\n",
      "Step 500: accuracy = 0.9441999793052673\n",
      "Step 600: accuracy = 0.9484000205993652\n",
      "Step 700: accuracy = 0.9613999724388123\n",
      "Step 800: accuracy = 0.9609000086784363\n",
      "Step 900: accuracy = 0.9617000222206116\n",
      "Step 1000: accuracy = 0.9645000100135803\n"
     ]
    }
   ],
   "source": [
    "mnist_saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restoring the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    ckpt_state = tf.train.get_checkpoint_state('ckpt/')\n",
    "    if ckpt_state:\n",
    "        last_model = ckpt_state.model_checkpoint_path\n",
    "        saver.restore(sess, last_model)\n",
    "        print('model was loaded:', last_model)\n",
    "    else:\n",
    "        sess.run(init)\n",
    "        print('initialized.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`last_model = ckpt_state.model_checkpoint_path`だと最新のモデルを読み込むことになるので、もしも任意のモデルを読み込みたい場合は以下のように指定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ckpt_state.all_model_checkpoint_paths[0] # the latest\n",
    "model = ckpt_state.all_model_checkpoint_paths[1] # the 2nd latest\n",
    "model = ckpt_state.all_model_checkpoint_paths[2] # the 3rd latest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
